# Notebook: Data Exploration
# 
# This notebook is for Phase 0.5: EDA & Sanity Baselines
#
# Goals:
# 1. Compute league-level P(G₂ > G₁) by league/season
# 2. Build naive baselines ("always 2H", "league prior only")
# 3. Establish minimum performance bar
#
# Convert to Jupyter notebook and run interactively.

# %% [markdown]
# # Phase 0.5: EDA & Sanity Baselines

# %%
# Imports
import pandas as pd
import numpy as np
from sqlalchemy import create_engine, text
import matplotlib.pyplot as plt
import seaborn as sns

# %%
# Connect to database
# from src.config import settings
# engine = create_engine(settings.database_url)

# For now, use sample data structure
# This will be filled once data is ingested

# %% [markdown]
# ## 1. League-Level P(G₂ > G₁)

# %%
# Query match outcomes
query = """
SELECT 
    league_code,
    season,
    COUNT(*) as total_matches,
    SUM(CASE WHEN actual_2h_gt_1h THEN 1 ELSE 0 END) as g2_wins,
    AVG(CASE WHEN actual_2h_gt_1h THEN 1.0 ELSE 0.0 END) as p_2h_gt_1h
FROM match_outcomes
WHERE status = 'FINISHED'
GROUP BY league_code, season
ORDER BY league_code, season
"""

# df = pd.read_sql(query, engine)
# print(df)

# %% [markdown]
# ## 2. Naive Baselines

# %%
# Baseline 1: "Always predict 2H"
# Accuracy = P(G₂ > G₁) overall

# Baseline 2: "League prior only"  
# Use league's historical rate as prediction

# These set the minimum bar our model must beat

# %% [markdown]
# ## 3. Visualizations

# %%
# Histogram of P(G₂ > G₁) by league
# fig, ax = plt.subplots(figsize=(10, 6))
# df.groupby('league_code')['p_2h_gt_1h'].mean().plot(kind='bar', ax=ax)
# ax.set_ylabel('P(G₂ > G₁)')
# ax.set_title('League-Level Baseline Probabilities')
# plt.xticks(rotation=45)
# plt.tight_layout()
